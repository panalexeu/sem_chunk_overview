{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c74e59d-7242-4eee-88b3-bca3406967b6",
   "metadata": {},
   "source": [
    "### semantic chunking experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e5e40-7538-467b-a6cd-75ba03e50c13",
   "metadata": {},
   "source": [
    "Required packages installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19563fbc-d46a-4537-8c8e-144e38651a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362412c0-3109-40a6-b2ca-001991888548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.4)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./.venv/lib/python3.12/site-packages (from langchain) (2.2.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.12/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers langchain seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68006ff-7345-465d-8378-f7895b32889f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ -----------\n",
      "aiohappyeyeballs         2.4.4\n",
      "aiohttp                  3.11.11\n",
      "aiosignal                1.3.2\n",
      "annotated-types          0.7.0\n",
      "anyio                    4.7.0\n",
      "asttokens                3.0.0\n",
      "attrs                    24.3.0\n",
      "certifi                  2024.12.14\n",
      "charset-normalizer       3.4.0\n",
      "comm                     0.2.2\n",
      "contourpy                1.3.1\n",
      "cycler                   0.12.1\n",
      "debugpy                  1.8.11\n",
      "decorator                5.1.1\n",
      "executing                2.1.0\n",
      "filelock                 3.16.1\n",
      "fonttools                4.55.3\n",
      "frozenlist               1.5.0\n",
      "fsspec                   2024.12.0\n",
      "greenlet                 3.1.1\n",
      "h11                      0.14.0\n",
      "httpcore                 1.0.7\n",
      "httpx                    0.28.1\n",
      "huggingface-hub          0.27.0\n",
      "idna                     3.10\n",
      "ipykernel                6.29.5\n",
      "ipython                  8.31.0\n",
      "jedi                     0.19.2\n",
      "Jinja2                   3.1.5\n",
      "joblib                   1.4.2\n",
      "jsonpatch                1.33\n",
      "jsonpointer              3.0.0\n",
      "jupyter_client           8.6.3\n",
      "jupyter_core             5.7.2\n",
      "kiwisolver               1.4.7\n",
      "langchain                0.3.13\n",
      "langchain-core           0.3.28\n",
      "langchain-text-splitters 0.3.4\n",
      "langsmith                0.2.4\n",
      "MarkupSafe               3.0.2\n",
      "matplotlib               3.10.0\n",
      "matplotlib-inline        0.1.7\n",
      "mpmath                   1.3.0\n",
      "multidict                6.1.0\n",
      "nest-asyncio             1.6.0\n",
      "networkx                 3.4.2\n",
      "numpy                    2.2.1\n",
      "nvidia-cublas-cu12       12.4.5.8\n",
      "nvidia-cuda-cupti-cu12   12.4.127\n",
      "nvidia-cuda-nvrtc-cu12   12.4.127\n",
      "nvidia-cuda-runtime-cu12 12.4.127\n",
      "nvidia-cudnn-cu12        9.1.0.70\n",
      "nvidia-cufft-cu12        11.2.1.3\n",
      "nvidia-curand-cu12       10.3.5.147\n",
      "nvidia-cusolver-cu12     11.6.1.9\n",
      "nvidia-cusparse-cu12     12.3.1.170\n",
      "nvidia-nccl-cu12         2.21.5\n",
      "nvidia-nvjitlink-cu12    12.4.127\n",
      "nvidia-nvtx-cu12         12.4.127\n",
      "orjson                   3.10.12\n",
      "packaging                24.2\n",
      "pandas                   2.2.3\n",
      "parso                    0.8.4\n",
      "pexpect                  4.9.0\n",
      "pillow                   11.0.0\n",
      "pip                      24.2\n",
      "platformdirs             4.3.6\n",
      "prompt_toolkit           3.0.48\n",
      "propcache                0.2.1\n",
      "psutil                   6.1.1\n",
      "ptyprocess               0.7.0\n",
      "pure_eval                0.2.3\n",
      "pydantic                 2.10.4\n",
      "pydantic_core            2.27.2\n",
      "Pygments                 2.18.0\n",
      "pyparsing                3.2.0\n",
      "python-dateutil          2.9.0.post0\n",
      "pytz                     2024.2\n",
      "PyYAML                   6.0.2\n",
      "pyzmq                    26.2.0\n",
      "regex                    2024.11.6\n",
      "requests                 2.32.3\n",
      "requests-toolbelt        1.0.0\n",
      "safetensors              0.4.5\n",
      "scikit-learn             1.6.0\n",
      "scipy                    1.14.1\n",
      "seaborn                  0.13.2\n",
      "sentence-transformers    3.3.1\n",
      "setuptools               75.6.0\n",
      "six                      1.17.0\n",
      "sniffio                  1.3.1\n",
      "SQLAlchemy               2.0.36\n",
      "stack-data               0.6.3\n",
      "sympy                    1.13.1\n",
      "tenacity                 9.0.0\n",
      "threadpoolctl            3.5.0\n",
      "tokenizers               0.21.0\n",
      "torch                    2.5.1\n",
      "tornado                  6.4.2\n",
      "tqdm                     4.67.1\n",
      "traitlets                5.14.3\n",
      "transformers             4.47.1\n",
      "triton                   3.1.0\n",
      "typing_extensions        4.12.2\n",
      "tzdata                   2024.2\n",
      "urllib3                  2.3.0\n",
      "wcwidth                  0.2.13\n",
      "yarl                     1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528ceee-b4e3-48a1-b22c-0b7df1b79610",
   "metadata": {},
   "source": [
    "[Documents](https://paulgraham.com/mit.html) (A Student's Guide to Startups, Paul Graham) for chunking evaluation uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6e0754-9b1e-4f1d-b5c7-b80794d3fa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A Student's Guide to Startups\\n\\nWant to start a startup? Get funded by Y Combinator.\\n\\nOctober 2006\\n\\n(This essay is derived from a talk at MIT.)\\n\\nTill recently graduating seniors had two choices: get a job or go to grad school. I think there will increasingl\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./paul_graham_essay.txt', 'r') as file:\n",
    "    essay = file.read()\n",
    "\n",
    "essay[:256]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742abf4-9f2c-4777-9395-25ccc9503448",
   "metadata": {},
   "source": [
    "Splitting the uploaded document by sentences (.!?)\\s+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d35dd859-f3c8-4dda-adb4-3e667e0d910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n",
      "[\"A Student's Guide to Startups\\n\\nWant to start a startup?\", 'Get funded by Y Combinator.', 'October 2006\\n\\n(This essay is derived from a talk at MIT.)\\n\\nTill recently graduating seniors had two choices: get a job or go to grad school.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "split_essay = re.split(r'(?<=[.!?])\\s+', essay)\n",
    "print(len(split_essay))\n",
    "print(split_essay[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939021b3-2bf6-44c5-9612-2ac3b7864bcf",
   "metadata": {},
   "source": [
    "Researhing the way embeddings behave on the paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23edea2f-248f-4d75-9184-fb9d39e248b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school.\",\n",
       " \"In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups.\",\n",
       " \"I wouldn't be surprised if that situation returns, but with one difference: this time they'll be starting their own instead of going to work for other people's.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = split_essay[5:8]\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa3054c-a144-493f-bd39-32c21c39cf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The most ambitious students will at this point be asking: Why wait till you graduate?',\n",
       " \"Why not start a startup while you're in college?\",\n",
       " 'In fact, why go to college at all?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = split_essay[8:11]\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dcb6857-98ed-4b47-bc2f-4b257c89fdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why not start a startup instead?',\n",
       " 'A year and a half ago I gave a talk where I said that the average age of the founders of Yahoo, Google, and Microsoft was 24, and that if grad students could start startups, why not undergrads?',\n",
       " \"I'm glad I phrased that as a question, because now I can pretend it wasn't merely a rhetorical one.\",\n",
       " \"At the time I couldn't imagine why there should be any lower limit for the age of startup founders.\",\n",
       " 'Graduation is a bureaucratic change, not a biological one.',\n",
       " 'And certainly there are undergrads as competent technically as most grad students.',\n",
       " \"So why shouldn't undergrads be able to start startups as well as grad students?\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3 = split_essay[11:18]\n",
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db19a15b-ddcd-472f-a1fe-a9221bbbf539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I now realize that something does change at graduation: you lose a huge excuse for failing.',\n",
       " \"Regardless of how complex your life is, you'll find that everyone else, including your family and friends, will discard all the low bits and regard you as having a single occupation at any given time.\",\n",
       " \"If you're in college and have a summer job writing software, you still read as a student.\",\n",
       " \"Whereas if you graduate and get a job programming, you'll be instantly regarded by everyone as a programmer.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4 = split_essay[18:22]\n",
    "p4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2844e331-ef10-4242-b450-fde5a098f8cd",
   "metadata": {},
   "source": [
    "Defining sentence transformer model to use. Specifically, all-mpnet-base-v2 (based on the [stats](https://sbert.net/docs/sentence_transformer/pretrained_models.html) it performs the best, from the locally hosted models options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56bc9b9b-f30e-45f6-a9ef-0323ef870900",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleksii/python/semantic_chunking/sem_chunk_overview/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d5a9d-8ec1-446f-9c92-ee1aa82fb4cc",
   "metadata": {},
   "source": [
    "Cosine similarity between embeddings calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11eb9564-abcc-4575-891f-b97538e658e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school.\", \"In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups.\", \"I wouldn't be surprised if that situation returns, but with one difference: this time they'll be starting their own instead of going to work for other people's.\"]\n",
      "cosine\n",
      "tensor([[1.0000, 0.5907, 0.3787],\n",
      "        [0.5907, 1.0000, 0.4760],\n",
      "        [0.3787, 0.4760, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(p1)\n",
    "model.similarity(embeddings, embeddings)\n",
    "print(p1)\n",
    "print(model.similarity_fn_name)\n",
    "print(model.similarity(embeddings, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee131a1-dc46-469f-bae3-78e4b2a4bc69",
   "metadata": {},
   "source": [
    "Testing the sliding window approach. I am trying to form consecutively bigger chunks by adding sentences one-by-one. The biggest chunk will consist of all sentences in the paragraph. In this particular case we form chunks from only one paragraph, then embed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2618421-884e-4fff-b77e-441a517499ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school.\",\n",
       " \" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school. In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups.\",\n",
       " \" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school. In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups. I wouldn't be surprised if that situation returns, but with one difference: this time they'll be starting their own instead of going to work for other people's.\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev = ''\n",
    "chunks = []\n",
    "for sentence in p1:\n",
    "    res = prev + ' ' + sentence\n",
    "    chunks.append(res)\n",
    "    prev = res\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75267e5-c382-444b-8d37-e8f61be24526",
   "metadata": {},
   "source": [
    "After the chunks embedding calculation, we see how the distance consecutively and slowly drifts away from the first chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fafa6302-ee41-4a5c-9042-291de0c324a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9266, 0.9116],\n",
       "        [0.9266, 1.0000, 0.9905],\n",
       "        [0.9116, 0.9905, 1.0000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode(chunks)\n",
    "model.similarity(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd7f1c-c840-4c7f-87bd-e98e714387ef",
   "metadata": {},
   "source": [
    "Let's mix two paragraphs together. Paragraphs mark that the chunks of text, by the intention of the author, have different semantic meaning. Let's will be able see that with the sliding window approach, just like in the previos case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d679007-763d-4f1d-b8b8-a087d51b24b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school.\",\n",
       " \" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school. In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups.\",\n",
       " \" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school. In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups. I wouldn't be surprised if that situation returns, but with one difference: this time they'll be starting their own instead of going to work for other people's.\",\n",
       " \" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school. In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups. I wouldn't be surprised if that situation returns, but with one difference: this time they'll be starting their own instead of going to work for other people's. The most ambitious students will at this point be asking: Why wait till you graduate?\",\n",
       " \" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school. In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups. I wouldn't be surprised if that situation returns, but with one difference: this time they'll be starting their own instead of going to work for other people's. The most ambitious students will at this point be asking: Why wait till you graduate? Why not start a startup while you're in college?\",\n",
       " \" I'm sure the default will always be to get a job, but starting a startup could well become as popular as grad school. In the late 90s my professor friends used to complain that they couldn't get grad students, because all the undergrads were going to work for startups. I wouldn't be surprised if that situation returns, but with one difference: this time they'll be starting their own instead of going to work for other people's. The most ambitious students will at this point be asking: Why wait till you graduate? Why not start a startup while you're in college? In fact, why go to college at all?\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev = ''\n",
    "mixed_chunks = []\n",
    "for sentence in [*p1, *p2]:\n",
    "    res = prev + ' ' + sentence\n",
    "    mixed_chunks.append(res)\n",
    "    prev = res\n",
    "\n",
    "mixed_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04272c6-c31b-4b64-91c0-a6873a2e466e",
   "metadata": {},
   "source": [
    "Once again we see the same pattern. The distance slowly drifts away. The main quesiton arises. How to understand where the edge is? How to find the threshold value to use? Those questions yet to be answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a5106d8-1426-4d46-9103-9fd43d8acba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9266, 0.9116, 0.8851, 0.8701, 0.8668],\n",
       "        [0.9266, 1.0000, 0.9905, 0.9698, 0.9663, 0.9607],\n",
       "        [0.9116, 0.9905, 1.0000, 0.9805, 0.9725, 0.9661],\n",
       "        [0.8851, 0.9698, 0.9805, 1.0000, 0.9922, 0.9878],\n",
       "        [0.8701, 0.9663, 0.9725, 0.9922, 1.0000, 0.9984],\n",
       "        [0.8668, 0.9607, 0.9661, 0.9878, 0.9984, 1.0000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode(mixed_chunks)\n",
    "model.similarity(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a102532-3063-4946-8dfc-34a269610e6a",
   "metadata": {},
   "source": [
    "Let's basically formulate the algorithm idea we have for now:\n",
    "1. Set the threshold value, for instance 0.9.\n",
    "2. While the threshold value is not passed:\n",
    "   \n",
    "   2.1 Iteratively take the next sentence and add it to the previous iteration's chunk.\n",
    "   \n",
    "   2.2 Calculate the embedding of the newly created chunk. \n",
    "\n",
    "   2.3 If the value of the distance between the new chunk's embedding and the initial sentence exceeds or equals the threshold => continue.\n",
    "\n",
    "   2.4 Otherwise, stop the iteration.\n",
    "\n",
    "The last chunk before the stop is a formed semantic unit. We further can rerun the algorithm starting from the sentence, which broke the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abd71a-dc53-4268-a6da-e96cdac4a307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem_chunk_overview kernel",
   "language": "python",
   "name": "sem_chunk_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
